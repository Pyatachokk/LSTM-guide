{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "batch_size = 1\n",
    "sample_size = 1\n",
    "sequence_length = 1\n",
    "learning_rate = 0.01\n",
    "hidden_layer_size = 10\n",
    "\n",
    "\n",
    "def norm_array(array):\n",
    "    mean = np.mean(array)\n",
    "    stddev = np.sqrt(np.sum(np.square(array - mean)) / len(array - 1))\n",
    "    normalized_array = ((array - mean) / stddev)\n",
    "    return normalized_array, mean.reshape(batch_size), stddev.reshape(batch_size)\n",
    "\n",
    "def norm_test(array, mean, stddev):\n",
    "    return (array - mean) / stddev\n",
    "\n",
    "def test_decoder(array, mean, stddev):\n",
    "    return (array * stddev) + mean\n",
    "\n",
    "def get_linear_layer(vector):\n",
    "    return(tf.matmul(vector, Wl) + bl)\n",
    "def train_test_split(X, y, train_size):\n",
    "    X_train = X[:int(len(X) // (1 / train_size))]\n",
    "    y_train = y[:int(len(y) // (1 / train_size))]\n",
    "    X_test = X[int(len(X) // (1 / train_size)):]\n",
    "    y_test = y[int(len(y) // (1 / train_size)):]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def data_labels(data, sample_size, batch_size):\n",
    "    labels = data.iloc[:sample_size, 2:]\n",
    "    data = data.iloc[:sample_size, 1:]\n",
    "    indeces = np.random.choice(len(data), size=batch_size, replace=False)\n",
    "    batch_x = np.array(data.loc[indeces[0]][data.loc[indeces[0]][:] > 0][:-1])\n",
    "    batch_y = np.array(labels.loc[indeces[0]][labels.loc[indeces[0]][:] > 0])\n",
    "    return (batch_x, batch_y)\n",
    "\n",
    "\n",
    "def cell_list(num_LSTM_layers):\n",
    "    cell_list = []\n",
    "    for i in range(num_LSTM_layers):\n",
    "        cell_list.append(tf.contrib.rnn.BasicLSTMCell(hidden_layer_size, forget_bias=1.0))\n",
    "    return cell_list\n",
    "\n",
    "def mse_diff(mse_batch_old, mse_batch_new):\n",
    "    return ((mse_batch_old - mse_batch_new)**2)**(1/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monthly = pd.read_csv(r\"C:\\M4datasets\\Monthly-train.csv\")\n",
    "data_month, labels_month = data_labels(data_monthly, sample_size = 1, batch_size = 1)\n",
    "data_month = data_month[:90]\n",
    "labels_month = labels_month[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = [1, 2, 3, 4, 5]\n",
    "num_hidden = [1, 2, 5, 10, 15, 20, 30, 50, 75, 100, 125, 150, 200]\n",
    "param_list = [(x, y) for x in num_layers for y in num_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria: 2562456.0 Iter: 0\n",
      "(1, 1) [] 0 1674361.6666666667\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 2236004.222222222 Iter: 0\n",
      "(1, 2) [] 0 1343173.2222222222\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 1885492.888888889 Iter: 0\n",
      "(1, 5) [] 0 741012.7777777778\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 1621531.111111111 Iter: 0\n",
      "(1, 10) [] 0 563277.8888888889\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 1609398.888888889 Iter: 0\n",
      "(1, 15) [] 0 536217.1666666666\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 1721793.111111111 Iter: 0\n",
      "(1, 20) [] 0 565455.8333333334\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 1124793.4444444445 Iter: 0\n",
      "(1, 30) [] 0 913679.1111111111\n",
      "Criteria: 0.0 Iter: 1\n",
      "Criteria: 821834.111111111 Iter: 0\n",
      "(1, 50) [] 0 1161558.6666666667\n",
      "Criteria: 0.0 Iter: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e1435e9bea5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSTM_cell'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcell_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_LSTM_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    580\u001b[0m       \u001b[1;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_transpose_batch_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mparallel_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    580\u001b[0m       \u001b[1;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_transpose_batch_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mparallel_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_transpose_batch_time\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mx\u001b[0m \u001b[0mtransposed\u001b[0m \u001b[0malong\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m   \"\"\"\n\u001b[1;32m---> 63\u001b[1;33m   \u001b[0mx_static_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mx_static_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx_static_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    472\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;34m\"\"\"Alias of Tensor.shape.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0mneed_shapes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mneed_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m           \u001b[0mset_shape_and_handle_data_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shape_and_handle_data_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2564\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_USE_C_SHAPES\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2566\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2567\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2568\u001b[0m       \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2220\u001b[0m     \u001b[1;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2222\u001b[1;33m       \u001b[0mop_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2223\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mop_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2224\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_list = []\n",
    "for param in param_list:\n",
    "    num_LSTM_layers = param[0]\n",
    "    hidden_layer_size = param[1]\n",
    "    tf.reset_default_graph()\n",
    "    with tf.name_scope(\"Training_data\"):\n",
    "        inputs = tf.placeholder(tf.float32,shape=[batch_size, None, sequence_length], name='inputs')\n",
    "        y = tf.placeholder(tf.float32, shape=[batch_size], name='inputs')\n",
    "\n",
    "    with tf.name_scope('Linear_weights_and_biases'):\n",
    "        Wl = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes], mean = 0, stddev = 0.01))\n",
    "        bl = tf.Variable(tf.truncated_normal([num_classes], mean = 0, stddev = 0.1))\n",
    "\n",
    "    with tf.name_scope('Means_and_standard_deviations'):\n",
    "        mean = tf.placeholder(tf.float32, shape = [batch_size])\n",
    "        stddev = tf.placeholder(tf.float32, shape = [batch_size])\n",
    "\n",
    "    with tf.variable_scope('LSTM_cell'):  \n",
    "        cell = tf.contrib.rnn.MultiRNNCell(cells=cell_list(num_LSTM_layers), state_is_tuple=True)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    with tf.variable_scope('Batch_outputs'):\n",
    "        final_outputs = tf.placeholder\n",
    "\n",
    "    linear_output = get_linear_layer(outputs[0])\n",
    "    final_output = test_decoder(linear_output, mean, stddev)[-1]\n",
    "    mse = tf.reduce_mean(tf.squared_difference(final_output, y[0]))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(mse)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    mse_list = []\n",
    "    mse_batch_old = 1e-10\n",
    "    for i in range(2):\n",
    "        batch_x, batch_y = data_month, labels_month\n",
    "        data_train, data_test, labels_train, labels_test = train_test_split(batch_x, batch_y, train_size = 0.8)\n",
    "\n",
    "        normed_data_train, mean_batch, stddev_batch = norm_array(data_train)\n",
    "\n",
    "        normed_data_train = normed_data_train.reshape(batch_size, len(data_train), sequence_length)\n",
    "\n",
    "        label = labels_train[-1].reshape(batch_size)\n",
    "        sess.run(train_step, feed_dict = {inputs : normed_data_train,\\\n",
    "                                                y : label,  mean : mean_batch, stddev : stddev_batch})\n",
    "        mse_batch = sess.run(mse, feed_dict = {inputs : normed_data_train,\\\n",
    "                                                y : label,  mean : mean_batch, stddev : stddev_batch})\n",
    "        for j in range(len(data_test)):\n",
    "            data_train =  np.append(data_train, data_test[j])\n",
    "            labels_train = np.append(labels_train, labels_test[j])\n",
    "            normed_data_train, mean_batch, stddev_batch = norm_array(data_train)\n",
    "            normed_data_train = normed_data_train.reshape(batch_size, len(data_train), sequence_length)\n",
    "\n",
    "            label = labels_train[-1].reshape(batch_size)\n",
    "            sess.run(train_step, feed_dict = {inputs : normed_data_train, y : label, mean : mean_batch, stddev : stddev_batch})\n",
    "            mse_batch += sess.run(mse, feed_dict = {inputs : normed_data_train,\\\n",
    "                                                y : label,  mean : mean_batch, stddev : stddev_batch})\n",
    "        mse_batch_new = mse_batch / len(data_test)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Criteria:\",mse_diff(mse_batch_old, mse_batch_new), \"Iter:\", i)\n",
    "        if mse_batch_new <= 1:\n",
    "            stop_list.append(i)\n",
    "            mse_batch_old = mse_batch_new\n",
    "            break\n",
    "        if mse_diff(mse_batch_old, mse_batch_new) < 0.001 and mse_batch_new > 1 :\n",
    "            stop_list.append(2000)\n",
    "            mse_batch_old = mse_batch_new\n",
    "            break\n",
    "        mse_batch_old = mse_batch_new\n",
    "        if i == 1999:\n",
    "            stop_list.append(2000)\n",
    "            break\n",
    "        if mse_batch_old < 5000:\n",
    "            learning_rate == learning_rate / ((i+1) * 10000)\n",
    "       \n",
    "    print(param, len(stop_list), mse_batch_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
